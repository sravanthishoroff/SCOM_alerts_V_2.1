{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re, pickle\n",
    "le = LabelEncoder()\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Server name</th>\n",
       "      <th>Summary of the alert</th>\n",
       "      <th>Description</th>\n",
       "      <th>MonitoringObjectDisplayName</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Category</th>\n",
       "      <th>TimeRaised</th>\n",
       "      <th>TimeAdded</th>\n",
       "      <th>Type of the Alert (True or False)</th>\n",
       "      <th>Action to be taken</th>\n",
       "      <th>Ignorable or Non-Ignorable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Red Hat Enterprise Linux Server release 6.10 (...</td>\n",
       "      <td>ACPI daemon is not running</td>\n",
       "      <td>The ACPI daemon on server ukmlwmsw902.uk.pri.o...</td>\n",
       "      <td>Red Hat Enterprise Linux Server release 6.10 (...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Error</td>\n",
       "      <td>AvailabilityHealth</td>\n",
       "      <td>2020-05-25 16:30:51</td>\n",
       "      <td>2020-05-25 16:28:53</td>\n",
       "      <td>True</td>\n",
       "      <td>Mail to Wintel Server Applications</td>\n",
       "      <td>Non-Ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Data Warehouse Synchronization Service</td>\n",
       "      <td>Alert data collection process unable to write ...</td>\n",
       "      <td>Alert data collection process unable to write ...</td>\n",
       "      <td>Data Warehouse Synchronization Service</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Error</td>\n",
       "      <td>StateCollection</td>\n",
       "      <td>2020-05-29 03:32:10</td>\n",
       "      <td>2020-05-29 02:30:05</td>\n",
       "      <td>True</td>\n",
       "      <td>Raise INC to DB support</td>\n",
       "      <td>Non-Ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>UKSTHSQL009.uk.pri.o2.com</td>\n",
       "      <td>Alert generation was temporarily suspended due...</td>\n",
       "      <td>A rule has generated 50 alerts in the last 60 ...</td>\n",
       "      <td>UKSTHSQL009.uk.pri.o2.com</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Alert</td>\n",
       "      <td>2020-05-31 21:17:03</td>\n",
       "      <td>2020-05-31 21:15:06</td>\n",
       "      <td>True</td>\n",
       "      <td>mail to wintel server support</td>\n",
       "      <td>Non-ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UKSTHSQL009.uk.pri.o2.com</td>\n",
       "      <td>Alert generation was temporarily suspended due...</td>\n",
       "      <td>A rule has generated 50 alerts in the last 60 ...</td>\n",
       "      <td>UKSTHSQL009.uk.pri.o2.com</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Alert</td>\n",
       "      <td>2020-05-18 21:36:48</td>\n",
       "      <td>2020-05-18 21:35:36</td>\n",
       "      <td>True</td>\n",
       "      <td>mail to wintel server support</td>\n",
       "      <td>Non-ignorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>UKDMZSOM005.uk.pri.o2.com</td>\n",
       "      <td>Alert Parameter Replacement Failure</td>\n",
       "      <td>Failed to replace parameter while creating the...</td>\n",
       "      <td>UKDMZSOM005.uk.pri.o2.com</td>\n",
       "      <td>Low</td>\n",
       "      <td>Warning</td>\n",
       "      <td>Alert</td>\n",
       "      <td>2020-05-24 20:30:49</td>\n",
       "      <td>2020-05-24 20:28:49</td>\n",
       "      <td>True</td>\n",
       "      <td>Can be ignored</td>\n",
       "      <td>Ignorable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Server name   \\\n",
       "0  Red Hat Enterprise Linux Server release 6.10 (...   \n",
       "1             Data Warehouse Synchronization Service   \n",
       "2                          UKSTHSQL009.uk.pri.o2.com   \n",
       "3                          UKSTHSQL009.uk.pri.o2.com   \n",
       "4                          UKDMZSOM005.uk.pri.o2.com   \n",
       "\n",
       "                                Summary of the alert  \\\n",
       "0                         ACPI daemon is not running   \n",
       "1  Alert data collection process unable to write ...   \n",
       "2  Alert generation was temporarily suspended due...   \n",
       "3  Alert generation was temporarily suspended due...   \n",
       "4                Alert Parameter Replacement Failure   \n",
       "\n",
       "                                         Description  \\\n",
       "0  The ACPI daemon on server ukmlwmsw902.uk.pri.o...   \n",
       "1  Alert data collection process unable to write ...   \n",
       "2  A rule has generated 50 alerts in the last 60 ...   \n",
       "3  A rule has generated 50 alerts in the last 60 ...   \n",
       "4  Failed to replace parameter while creating the...   \n",
       "\n",
       "                         MonitoringObjectDisplayName Priority Severity  \\\n",
       "0  Red Hat Enterprise Linux Server release 6.10 (...   Normal    Error   \n",
       "1             Data Warehouse Synchronization Service   Normal    Error   \n",
       "2                          UKSTHSQL009.uk.pri.o2.com   Normal  Warning   \n",
       "3                          UKSTHSQL009.uk.pri.o2.com   Normal  Warning   \n",
       "4                          UKDMZSOM005.uk.pri.o2.com      Low  Warning   \n",
       "\n",
       "             Category          TimeRaised           TimeAdded  \\\n",
       "0  AvailabilityHealth 2020-05-25 16:30:51 2020-05-25 16:28:53   \n",
       "1     StateCollection 2020-05-29 03:32:10 2020-05-29 02:30:05   \n",
       "2               Alert 2020-05-31 21:17:03 2020-05-31 21:15:06   \n",
       "3               Alert 2020-05-18 21:36:48 2020-05-18 21:35:36   \n",
       "4               Alert 2020-05-24 20:30:49 2020-05-24 20:28:49   \n",
       "\n",
       "  Type of the Alert (True or False)                 Action to be taken   \\\n",
       "0                              True  Mail to Wintel Server Applications   \n",
       "1                              True             Raise INC to DB support   \n",
       "2                              True      mail to wintel server support    \n",
       "3                              True      mail to wintel server support    \n",
       "4                              True                      Can be ignored   \n",
       "\n",
       "  Ignorable or Non-Ignorable  \n",
       "0              Non-Ignorable  \n",
       "1              Non-Ignorable  \n",
       "2              Non-ignorable  \n",
       "3              Non-ignorable  \n",
       "4                  Ignorable  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r\"scom2016-alert-02-06-2020 Updated.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Server name ', 'Summary of the alert', 'Description',\n",
       "       'MonitoringObjectDisplayName', 'Priority', 'Severity', 'Category',\n",
       "       'TimeRaised', 'TimeAdded', 'Type of the Alert (True or False)',\n",
       "       'Action to be taken ', 'Ignorable or Non-Ignorable'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Summary of the alert','Ignorable or Non-Ignorable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Summary of the alert', 'Ignorable or Non-Ignorable'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-ignorable    10615\n",
       "Ignorable         2539\n",
       "Non-Ignorable      775\n",
       "Name: Ignorable or Non-Ignorable, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Ignorable or Non-Ignorable'] = df1['Ignorable or Non-Ignorable'].replace(to_replace='Non-ignorable',value='Non-Ignorable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Ignorable    11390\n",
       "Ignorable         2539\n",
       "Name: Ignorable or Non-Ignorable, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Ignorable or Non-Ignorable']=df1['Ignorable or Non-Ignorable'].apply(lambda x: 1 if (x)==\"Non-Ignorable\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11390\n",
       "0     2539\n",
       "Name: Ignorable or Non-Ignorable, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               ACPI daemon is not running\n",
       "1        Alert data collection process unable to write ...\n",
       "2        Alert generation was temporarily suspended due...\n",
       "3        Alert generation was temporarily suspended due...\n",
       "4                      Alert Parameter Replacement Failure\n",
       "                               ...                        \n",
       "13924                         XenApp MP Agent Installation\n",
       "13925                         XenApp MP Agent Installation\n",
       "13926                         XenApp MP Agent Installation\n",
       "13927                         XenApp MP Agent Installation\n",
       "13928                         XenApp MP Agent Installation\n",
       "Name: Summary of the alert, Length: 13929, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13929,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13929,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "13924    0\n",
       "13925    0\n",
       "13926    0\n",
       "13927    0\n",
       "13928    0\n",
       "Name: Ignorable or Non-Ignorable, Length: 13929, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Ignorable or Non-Ignorable'].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Summary of the alert'] = df1['Summary of the alert'].apply(lambda x: x.lower())\n",
    "# df['Alert'] = df['Alert'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Summary of the alert'] = df1['Summary of the alert'].apply(lambda s: re.sub(r\"[^a-zA-Z0-9]\",\" \",s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\SRAVANTHI\n",
      "[nltk_data]     SHOROFF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens =[w for w in tokens if not w in stop_words] # [w for w in\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in tokens])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      acpi daemon running\n",
       "1        alert data collection process unable write dat...\n",
       "2        alert generation temporarily suspended due man...\n",
       "3        alert generation temporarily suspended due man...\n",
       "4                      alert parameter replacement failure\n",
       "                               ...                        \n",
       "13924                         xenapp mp agent installation\n",
       "13925                         xenapp mp agent installation\n",
       "13926                         xenapp mp agent installation\n",
       "13927                         xenapp mp agent installation\n",
       "13928                         xenapp mp agent installation\n",
       "Name: Summary of the alert, Length: 13929, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Summary of the alert'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector=TfidfVectorizer(use_idf=True,max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tfidf_vector.fit_transform(df1['Summary of the alert']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.29065627, 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.51889051],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.51889051],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.51889051]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_dump_ML\\\\scom'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tf, open(\"vectorized.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"vectorized.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking X and y\n",
    "X = vectorizer\n",
    "y = df1['Ignorable or Non-Ignorable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "\n",
      "***** Logistic Regression classification report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       674\n",
      "           1       1.00      1.00      1.00      2809\n",
      "\n",
      "    accuracy                           1.00      3483\n",
      "   macro avg       1.00      0.99      0.99      3483\n",
      "weighted avg       1.00      1.00      1.00      3483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "glmMod = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True,\n",
    "                            intercept_scaling=1, class_weight=None, \n",
    "                            random_state=None, solver='liblinear', max_iter=100,\n",
    "                            multi_class='ovr', verbose=2)\n",
    "glmMod.fit(X_train, y_train)\n",
    "y_pred=glmMod.predict(X_test)\n",
    "print(\"\\n\\n***** Logistic Regression classification report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lrMod1.pkl'\n",
    "pickle.dump(glmMod, open('lrMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** RandomForestClassifier report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       671\n",
      "           1       1.00      1.00      1.00      2812\n",
      "\n",
      "    accuracy                           1.00      3483\n",
      "   macro avg       1.00      1.00      1.00      3483\n",
      "weighted avg       1.00      1.00      1.00      3483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfMod = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                               random_state=None, verbose=0)\n",
    "rfMod.fit(X_train, y_train)\n",
    "y_pred=rfMod.predict(X_test)\n",
    "print(\"\\n\\n***** RandomForestClassifier report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rfMod1.pkl'\n",
    "pickle.dump(rfMod, open('rfMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** GradientBoosting report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       671\n",
      "           1       1.00      1.00      1.00      2812\n",
      "\n",
      "    accuracy                           1.00      3483\n",
      "   macro avg       1.00      1.00      1.00      3483\n",
      "weighted avg       1.00      1.00      1.00      3483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbMod = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,\n",
    "                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                   max_depth=3,\n",
    "                                   init=None, random_state=None, max_features=None, verbose=0)\n",
    "gbMod.fit(X_train, y_train)\n",
    "y_pred=gbMod.predict(X_test)\n",
    "print(\"\\n\\n***** GradientBoosting report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gbMod1.pkl'\n",
    "pickle.dump(rfMod, open('gbMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***** Adaboost report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       671\n",
      "           1       1.00      1.00      1.00      2812\n",
      "\n",
      "    accuracy                           1.00      3483\n",
      "   macro avg       0.99      1.00      1.00      3483\n",
      "weighted avg       1.00      1.00      1.00      3483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaMod = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)\n",
    "adaMod.fit(X_train, y_train)\n",
    "y_pred = adaMod.predict(X_test)\n",
    "print(\"\\n\\n***** Adaboost report:*****\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'adaMod1.pkl'\n",
    "pickle.dump(rfMod, open('adaMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]\n",
      "\n",
      "***** Model Ensemble score report:*****\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       671\n",
      "           1       1.00      1.00      1.00      2812\n",
      "\n",
      "    accuracy                           1.00      3483\n",
      "   macro avg       1.00      1.00      1.00      3483\n",
      "weighted avg       1.00      1.00      1.00      3483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingMod = VotingClassifier(estimators=[('RandomForrest', rfMod),('LogisticRegression', glmMod),(\"GradientBoosting\",gbMod),(\"AdaBoost\",adaMod)], voting='soft')\n",
    "votingMod = votingMod.fit(X_train, y_train)\n",
    "test_labels=votingMod.predict((X_test))\n",
    "#votingMod.score(X_test_transform, y_test)\n",
    "\n",
    "print(\"\\n\\n***** Model Ensemble score report:*****\\n\")\n",
    "print(classification_report(y_test, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'votingMod1.pkl'\n",
    "pickle.dump(rfMod, open('votingMod1.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_ML_v_3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13929"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10615+775+2539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pkl_file = 'C:\\\\Users\\\\SRAVANTHI SHOROFF\\\\Desktop\\\\sravanthi\\\\SCOM_ML_v_3\\\\votingMod1.pkl'\n",
    "with open(pkl_file,'rb') as file:\n",
    "        votingclassifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict class\n",
    "y_pred = votingclassifier.predict(X)\n",
    "print(y_pred)\n",
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = pd.DataFrame(columns=['y_pred'],data = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output['y_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-6863ff0f4ab9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predicted_value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "y_pred['predicted_value'] = y_pred\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['pred_val'] = output['y_pred'].replace(to_replace=1,value='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output['pred_val'] = output['y_pred'].replace(to_replace=0,value='No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    11389\n",
       "0       2540\n",
       "Name: pred_val, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['pred_val'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_output = output[output['pred_val']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(false_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
